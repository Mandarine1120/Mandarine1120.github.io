<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Natural language processing based on graph model | Mandarine&#39;s Blog</title>
    <meta name="generator" content="VuePress 1.7.1">
    <link rel="icon" href="/icon.jpg">
    <link rel="stylesheet" href="/iconfont/iconfont.css">
    <script language="javascript" type="text/javascript" src="/iconfont/iconfont.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/stevenjoezhang/live2d-widget@latest/autoload.js"></script>
    <meta name="description" content="Stay foolish，stay hungry">
    <meta name="keywords" content="Personal Blog">
    <meta name="baidu-site-verification" content="bdukCluk30">
    <meta name="sogou_site_verification" content="gReIJbnqBO">
    <meta name="author" content="MaNong">
    
    <link rel="preload" href="/assets/css/0.styles.35ed05a5.css" as="style"><link rel="preload" href="/assets/js/app.27afb4e8.js" as="script"><link rel="preload" href="/assets/js/2.5de855df.js" as="script"><link rel="preload" href="/assets/js/28.817b3fb7.js" as="script"><link rel="prefetch" href="/assets/js/10.c7a95e63.js"><link rel="prefetch" href="/assets/js/11.5fdd4582.js"><link rel="prefetch" href="/assets/js/12.6bf46332.js"><link rel="prefetch" href="/assets/js/13.f966b876.js"><link rel="prefetch" href="/assets/js/14.404c286c.js"><link rel="prefetch" href="/assets/js/15.d07b72f3.js"><link rel="prefetch" href="/assets/js/16.f87a493e.js"><link rel="prefetch" href="/assets/js/17.e84cf7d1.js"><link rel="prefetch" href="/assets/js/18.72c68d79.js"><link rel="prefetch" href="/assets/js/19.adfeda07.js"><link rel="prefetch" href="/assets/js/20.46257fca.js"><link rel="prefetch" href="/assets/js/21.5ce39f14.js"><link rel="prefetch" href="/assets/js/22.2231f217.js"><link rel="prefetch" href="/assets/js/23.dcce6f9d.js"><link rel="prefetch" href="/assets/js/24.19c132c6.js"><link rel="prefetch" href="/assets/js/25.76ee59cd.js"><link rel="prefetch" href="/assets/js/26.51268995.js"><link rel="prefetch" href="/assets/js/27.74938332.js"><link rel="prefetch" href="/assets/js/29.a983b12e.js"><link rel="prefetch" href="/assets/js/3.92b04179.js"><link rel="prefetch" href="/assets/js/30.4516a69d.js"><link rel="prefetch" href="/assets/js/31.dbee2696.js"><link rel="prefetch" href="/assets/js/32.a6598241.js"><link rel="prefetch" href="/assets/js/33.a58d0c62.js"><link rel="prefetch" href="/assets/js/34.50742376.js"><link rel="prefetch" href="/assets/js/35.dd9f1d7f.js"><link rel="prefetch" href="/assets/js/36.06650e87.js"><link rel="prefetch" href="/assets/js/37.24691b5f.js"><link rel="prefetch" href="/assets/js/38.74e797f9.js"><link rel="prefetch" href="/assets/js/39.a6219277.js"><link rel="prefetch" href="/assets/js/4.62620996.js"><link rel="prefetch" href="/assets/js/40.c95115a9.js"><link rel="prefetch" href="/assets/js/41.80c10e28.js"><link rel="prefetch" href="/assets/js/42.3d535e1d.js"><link rel="prefetch" href="/assets/js/5.a31a3149.js"><link rel="prefetch" href="/assets/js/6.b3324382.js"><link rel="prefetch" href="/assets/js/7.5e3c70f6.js"><link rel="prefetch" href="/assets/js/8.1ba1e942.js"><link rel="prefetch" href="/assets/js/9.8dc6c245.js">
    <link rel="stylesheet" href="/assets/css/0.styles.35ed05a5.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="/icon.jpg" alt="Mandarine's Blog" class="logo"> <span class="site-name can-hide">Mandarine's Blog</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/index.html" class="nav-link">
  Home page
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Knowledge" class="dropdown-title"><span class="title">Knowledge</span> <span class="arrow down"></span></button> <button type="button" aria-label="Knowledge" class="mobile-dropdown-title"><span class="title">Knowledge</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/views/Lessons/01-CS224W.html" class="nav-link">
  Lessons
</a></li><li class="dropdown-item"><!----> <a href="/views/Book/test.html" class="nav-link">
  Books
</a></li><li class="dropdown-item"><!----> <a href="/views/ML/01-文本图模型.html" class="nav-link">
  Survey
</a></li><li class="dropdown-item"><!----> <a href="/views/Interview/test.html" class="nav-link">
  Interview
</a></li><li class="dropdown-item"><!----> <a href="/views/funny/English.html" class="nav-link">
  Weird part
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Technology" class="dropdown-title"><span class="title">Technology</span> <span class="arrow down"></span></button> <button type="button" aria-label="Technology" class="mobile-dropdown-title"><span class="title">Technology</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/coms/code/test.html" class="nav-link">
  Algorithms
</a></li><li class="dropdown-item"><!----> <a href="/coms/model/test.html" class="nav-link">
  Models
</a></li><li class="dropdown-item"><!----> <a href="/coms/environment/1-install.html" class="nav-link">
  Environments
</a></li><li class="dropdown-item"><!----> <a href="/coms/tool/test.html" class="nav-link">
  Tools
</a></li></ul></div></div><div class="nav-item"><a href="/jottings/1-个人陈述.html" class="nav-link">
  Essay
</a></div><div class="nav-item"><a href="/about/" class="nav-link">
  About me
</a></div> <a href="https://github.com/Mandarine1120/Mandarine1120.github.io/" target="_blank" rel="noopener noreferrer" class="repo-link">
    Github
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/index.html" class="nav-link">
  Home page
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Knowledge" class="dropdown-title"><span class="title">Knowledge</span> <span class="arrow down"></span></button> <button type="button" aria-label="Knowledge" class="mobile-dropdown-title"><span class="title">Knowledge</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/views/Lessons/01-CS224W.html" class="nav-link">
  Lessons
</a></li><li class="dropdown-item"><!----> <a href="/views/Book/test.html" class="nav-link">
  Books
</a></li><li class="dropdown-item"><!----> <a href="/views/ML/01-文本图模型.html" class="nav-link">
  Survey
</a></li><li class="dropdown-item"><!----> <a href="/views/Interview/test.html" class="nav-link">
  Interview
</a></li><li class="dropdown-item"><!----> <a href="/views/funny/English.html" class="nav-link">
  Weird part
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Technology" class="dropdown-title"><span class="title">Technology</span> <span class="arrow down"></span></button> <button type="button" aria-label="Technology" class="mobile-dropdown-title"><span class="title">Technology</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/coms/code/test.html" class="nav-link">
  Algorithms
</a></li><li class="dropdown-item"><!----> <a href="/coms/model/test.html" class="nav-link">
  Models
</a></li><li class="dropdown-item"><!----> <a href="/coms/environment/1-install.html" class="nav-link">
  Environments
</a></li><li class="dropdown-item"><!----> <a href="/coms/tool/test.html" class="nav-link">
  Tools
</a></li></ul></div></div><div class="nav-item"><a href="/jottings/1-个人陈述.html" class="nav-link">
  Essay
</a></div><div class="nav-item"><a href="/about/" class="nav-link">
  About me
</a></div> <a href="https://github.com/Mandarine1120/Mandarine1120.github.io/" target="_blank" rel="noopener noreferrer" class="repo-link">
    Github
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav>  <ul class="sidebar-links"><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Lessons</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Books</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>Survey</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/views/ML/01-文本图模型.html" class="active sidebar-link">Natural language processing based on graph model</a></li><li><a href="/views/ML/02-频繁子图挖掘.html" class="sidebar-link">频繁子图挖掘</a></li><li><a href="/views/ML/03-图计算模型.html" class="sidebar-link">图计算模型</a></li><li><a href="/views/ML/04-图数据增强.html" class="sidebar-link">Graph Data Augmentation</a></li><li><a href="/views/ML/05-图对比学习.html" class="sidebar-link">Graph Contrastive Learning</a></li></ul></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Interview</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Weird part</span> <span class="arrow right"></span></p> <!----></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="text-graph"><a href="#text-graph" class="header-anchor">#</a> Text Graph</h1> <!----> <p>In the Natural language processing field, text graph or textual graph is a form of data model representing textual information and semantic relationship. It models the structure and semantics of text by representing words, phrases, or sentences as nodes in the graph, and using edges to represent their association relationships.</p> <p>Text graphs can capture various relationships within a text, such as co-occurrence relationships between words, similarity between sentences, correlations between concepts, contextual relationships, synonymous relationships, superlative relationships, etc. By analyzing and modeling these relationships in text, text graphs can provide more comprehensive semantic information and richer contextual understanding. This method is commonly used for text NLU, text classification, text summarization, relationship extraction, text implication tasks, etc.</p> <p>The definition of nodes and edges in text graphs is very broad. For nodes, they can be considered as individual words or sentences, domain specific terms, or entities mentioned in the text (which in this case devolves into relationship diagrams). For edges, they can be co-occurrence relationships, contextual relationships, subordinate relationships, and so on.</p> <p>Using textual graphs offers several benefits:</p> <ul><li>Capturing Semantic Associations: Textual graphs can capture semantic relationships within text, including associations between words, relevance between phrases, and similarity between sentences. By modeling these semantic relationships, textual graphs provide more comprehensive semantic information, aiding models in better understanding the meaning of text.</li> <li>Enhancing Contextual Understanding: Textual graphs can establish connections within the context of sentences or paragraphs, linking related information through edge associations. This helps models better comprehend information within the context, capturing relationships between contexts and improving the accurate understanding of the text.</li> <li>Integrating Multimodal Information: Textual graphs can be combined with information from other modalities such as images and audio, forming multimodal graphs. This integration is particularly useful when dealing with multimodal data, enabling a better representation and modeling of relationships between text and other modalities, achieving a more comprehensive understanding of information.</li> <li>Semantic Inference and Knowledge Extraction: Through textual graphs, semantic inference and knowledge extraction can be performed. For example, by analyzing relationships within the textual graph, one can engage in inference and deduction, uncovering hidden semantic relationships. Furthermore, textual graphs can extract essential concepts and key information from text, which can be utilized for knowledge representation and the construction of knowledge graphs.</li></ul> <h2 id="textgcn"><a href="#textgcn" class="header-anchor">#</a> TextGCN</h2> <p>Paper title: <strong>TextGCN：Graph Convolutional Networks for Text Classification</strong></p> <p>This paper constructs a text graph based on the co-occurrence relationship of the text and uses one-hot encoding as the initial feature. The paper applies GCN to text classification tasks, constructs a network model <strong>TextGCN</strong>, and conducts experimental verification on four long text datasets (20NG, R8, R52, Ohsumed) and one short text dataset (MR, movie short comment dataset).</p> <ul><li>Firstly, the paper constructs a large heterogeneous text graph network that includes word nodes and document nodes, so that global co-occurrence words can be clearly constructed.</li></ul> <img src="/img/Survey-textgraph-word.png" width="50%" height="50%" style="margin-bottom:-20px;"> <p>The number of nodes in the text graph network is the number of document nodes (the size of the dataset) plus the number of non repeating words contained in the dataset (the size of the vocabulary), as shown in the following figure.</p> <img src="/img/Survey-textgraph.png" style="margin-bottom:-20px;"> <ul><li><p>Afterwards, this paper made modifications on the basis of GCN, mainly proposing to construct a graph using the entire corpus. The nodes in the graph represent each document in the corpus and all words in the dictionary, and construct a large graph represented by an adjacency matrix. After constructing the graph and its adjacency matrix, use GCN for transfer calculations.</p></li> <li><p>Finally, this paper uses a two-layer GCN for model training and proves through experiments that the two-layer GCN performs better than single-layer or more than two-layer GCNs. Finally, the author conducted experimental comparisons on the selection of network parameters in this paper, and visualized the word vector learning of the model, demonstrating the effectiveness of GCN in document classification in multiple aspects. This indicates that graphs and their adjacency matrices in GCN can be constructed in various ways, such as the degree of correlation between words, the degree of correlation between words and documents, and even dependency trees. Therefore, proposing new graph construction methods is also an innovation in GCN's document classification.</p></li></ul> <h2 id="bertgcn"><a href="#bertgcn" class="header-anchor">#</a> BertGCN</h2> <p>Paper title: <strong>BertGCN: Transductive Text Classification by Combining GCN and BERT</strong></p> <p>BertGCN is also a two part Build Graph and Model Train.</p> <ol><li><p>Composition: The Build Graph section is the same as TextGCN, so I skipped it without any difference. Let's focus on the model section.</p></li> <li><p>Initialization: BertGCN does not use a random initialization strategy when initializing node embeddings, but instead uses Bert to process document nodes for initialization, while Word nodes are directly initialized to 0 for initial embeddings.</p></li> <li><p>Results and model training obtained by integrating BERT module and GCN module</p></li></ol> <p>$$
Z_{GCN}=softmax(g(X,A))
\
Z_{BERT}=softmax(WX)
\
Z = \lambda Z_{GCN} + (1-\lambda)Z_{BERT}
$$</p> <p>In the section of integrating Bert and GCN training, it is pointed out in this paper that embedding the Bert encoder into GCN and directly combining training will result in two problems,</p> <ol><li><p>During gradient feedback, the Bert part cannot achieve effective gradient optimization.</p></li> <li><p>GCN is a fully updated graph. Assuming that the graph has 10k document nodes, then the BERT part with 10k documents simultaneously undergoes BERT ENCODER to obtain document embedding, which is then thrown into the GCN layer for update training. This is obviously not achievable.</p></li></ol> <p>In response to these issues, this paper proposes an interpolation update method. The final interpolation update is to add up the two document embeddings obtained from GCN and Bert separately acting on the text to obtain the fusion classification probability Z, and then use the cross entropy loss function to make a classification prediction.</p> <p>Due to the existence of BERT, BertGCN can only load one batch at a time during training, rather than the entire graph. To address this issue, BertGCN used <strong>Memory Bank</strong>.</p> <p>It saved the features of all document nodes and separated the graph nodes from each batch during training. Each batch only needs to extract a small portion of the required node features from them.</p> <p>Simply put, the memory storage mechanism dynamically updates a small number of document nodes through each iteration, and uses these nodes to train the model. This avoids reading all features into BERT for calculation at once, greatly reducing memory overhead.</p> <p>However, one issue that arises from this is that due to the fact that document nodes are updated in batches, there may be inconsistencies in the features input into the model at different iterations of an Epoch. Therefore, BertGCN adopts a smaller learning rate when updating the BERT module to reduce inconsistencies between features. To accelerate training, BertGCN initializes the BERT module in BertGCN with a BERT model trained on a downstream dataset before training.</p> <!----></div> <footer class="page-edit"><!----> <div class="last-updated"><span class="prefix">Last update in:</span> <span class="time">9/8/2023, 4:28:15 PM</span></div></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/views/Book/test.html" class="prev">
        书籍笔记-异质图表示学习与应用
      </a></span> <span class="next"><a href="/views/ML/02-频繁子图挖掘.html">
        频繁子图挖掘
      </a>
      →
    </span></p></div> </main></div> <div class="home"><div class="footer"><a href="https://mandarine1120.github.io/about/#%E8%81%94%E7%B3%BB%E6%88%91" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Please contact me if you have any question about this page or this blog.
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div></div></div><div class="global-ui"><!----></div></div>
    <script src="/assets/js/app.27afb4e8.js" defer></script><script src="/assets/js/2.5de855df.js" defer></script><script src="/assets/js/28.817b3fb7.js" defer></script>
  </body>
</html>
